\chapter{Understanding Field Agent Behavior}\label{chap:2}
\begin{quote}
    ``It is a capital mistake to theorize before one has data.'' \\
    --- Sir Arthur Conan Doyle, \emph{Sherlock Holmes}
  \end{quote}

This chapter surveys gas pump inspection reports from the Arizona Department of Weights and Measures (AZDWM). It begins by attempting to attain descriptive statistics related to skimming from these documents. Challenges in attaining these statistics lead into discussion of data acquisition methodologies. This chapter then highlights discoveries about inspections and skimmers contained within the documents. It concludes with a summary of the motivation for Bluetana's development provided by the documents and future work. 

Analysis of the data provided by AZDWM proved to be difficult, but had two primary benefits. The first was a categorical understanding of current investigative techniques: notes provided by investigators offer insight into how they perform inspections. The second was an understanding of the potential avenues of skimmer detection. Photos and forms included in the reports reveal details of skimmer construction. These details suggest Bluetooth modules are commonly used and that Bluetooth is a potentially effective route for detection. 

Finally, This chapter functions as a \emph{case study} of exploratory data analysis. It does not provide universal techniques; instead, it compares multiple approaches to the analysis of gas station inspection documents. This structure allows the chapter to demonstrate some ways \emph{not} to do data analysis on this type of data set. It does so by comparing tempting, flawed data analysis techniques to ground-truth data. 
    
    \section{Survey Background}

Inspection report PDFs from the AZDWM are accessible through a queriable web interface (\url{https://ctutools.azda.gov/PdfOriginals/}). Thus, the data set of reports was retrieved via an html parser and batched \texttt{wget} requests. The PDFs downloaded from this source include documents unrelated to inspections. PDFs relating to inspection reports follow a naming scheme of \texttt{\{BMF \#\}-\{Inspection \#\}.(pdf|PDF)}. A BMF, or Business Master File, number is a unique identifier given to each business by the AZDWM \cite{azdwmLicensing}. It is not clear from the filenames which reports pertain to skimming.  Thus, classifying and analyzing these reports requires parsing the PDFs themselves. Luckily, reports contain a header that indicates the origin of the inspection.

    There are~\totalAZDWMpdfs~inspection report PDFs available on the AZDWM website. The oldest report available is from July 2010. This survey will focus on reports filed from the beginning of 2016 to the end of 2018. This amounts to a total of~\upperAZDWMpdfs~reports. By restricting analysis to the past three years of data, we preserve the relevance of the study to the present day. Table~\ref{tab:overview-azdwm-stats} provides overview statistics on the documents. 

\begin{table}
    \centering
    \noindent
    \begin{tabular}{l|c}
    \toprule
    Total Number of PDFs                                         & \upperAZDWMpdfs  \\
    \midrule
    Number of PDFs with Parsable Origin                          & \numParsableAZDWMpdfs   \\
    \midrule
    Number of PDFs Originating from a Skimmer Inspection         & \numSKIOrig  \\
    \midrule
    Number of PDFs with the word ``skimm''                       & \numSkimWord  \\
    \midrule
    Success Rate Reported by the AZDWM (Unhinted)                     & 1.5\%  \\
    \bottomrule
    \end{tabular}
    \caption{Overview statistics on the documents from AZDWM gas station inspection reports. Only a portion of the documents are parsable. Some non-skimmer inspections include checks for skimmers.}
    \label{tab:overview-azdwm-stats}
\end{table}

A primary goal of this survey is to understand how investigators perform skimmer inspections. For instance, how rigorously inspectors investigate pumps (Section~\ref{sec:inspector-behavior}). Another goal was to quantify the hit rate of skimmer inspections (Section~\ref{sec:document-data-extraction}); this provides a measure of how common skimming is. Additionally, it was important to determine how much room for improvement there is in detection methods. This was done by measuring how long inspections take to complete (Section~\ref{sec:insp-time-ana}). 

\section{Understanding the Documents}\label{sec:understanding-the-documents}

      Upon examining the PDFs, we find the information contained within is highly unstructured. For example, the documents have an inconsistent use of the 198 failure code. This code indicates a skimmer was found. Figure~\ref{fig:198-usages} depicts two different uses of this code. There also exist successful skimmer inspections with no 198 code in the document at all \cite{13529-268466}. Unfortunately, this indicates a single regular expression search for successful investigations is nontrivial. Additionally, there are latent ambiguities in the data collected. Many documents do not state whether a found skimmer was internal or external. They also do not indicate whether a given inspection called in by a gas station owner or other party. This would be the case if the station owner or service tech was responsible for the discovery of the skimmer.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/198-usages.png}
    \caption{
      Inconsistent use of the 198 error code. In the top report, the code is included in the inspection notes. In the bottom image, a separate field used for fail codes contains the 198.
    }
    \label{fig:198-usages}
\end{figure}

The exact skimmer inspection methodology is not noted in any of the reports. There are, however, hints within the inspection notes and the document structure. For instance, vapor recovery\footnote{Checking the pumps to make sure they do not leak gasoline vapors into the atmosphere.}  reports contain a pre-inspection checklist. This checklist contains a check for skimmers (Figure~\ref{fig:check-for-skimmers}). The reports do not contain information on the whether skimmer investigations occur alongside other inspections; however, the AZDWM site notes skimmer inspections are always performed during pump inspections \cite{azdwmSkimmers}. Thus, any report that includes a pump inspection includes a skimmer check.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/inspection-checklist.png}
    \caption{
	    Section of the inspection reports which demonstrates information on the pre-inspection checklist. In this case, no skimmer was found.
    }
    \label{fig:check-for-skimmers}
\end{figure}

The inspection reports also contain information on skimmer construction.
Some report forms have a checkbox for tagging whether a skimmer is SMS or Bluetooth enabled
(Figure~\ref{fig:bluetooth-or-gsm}).
However, inspectors may not have a perfect sense of this.
AZDWM has informed us Investigators do not to remove any tape used to encase or hide the skimmer in the pump.
This is done to preserve fingerprints 
\cite{20340-269297}.
Some documents do attempt to correlate Bluetooth features to discovered skimmers. 
For example, MAC addresses and skimmer names
(Figure~\ref{fig:mac-address-report}).
During the Bluetana study, these hints were found to be inaccurate.
However, they do illustrate some investigator awareness of Skimmers' Bluetooth capabilities.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/bluetooth-or-gsm.png}
    \caption{
      Some inspection forms include a checkbox for the exfiltration mechanism of the skimmer.
      While the selection of SMS may not be accurate, it does indicate not all skimmers use Bluetooth.
    }
    \label{fig:bluetooth-or-gsm}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/mac-address-report.png}
    \caption{
	    Section of the inspection reports noting a potential MAC address for a skimmer.
      Follow up investigation found this MAC address to be uncorrelated with skimmer discovery.
    }
    \label{fig:mac-address-report}
\end{figure}

    \subsection{Understanding Document Origins}

Inspection reports have~\numorigins~different origin headers.
Table \ref{tab:explanations-of-origins}
contains statistics and descriptions of the different report types.
Regular, scheduled inspections are the most common, followed by skimmer inspections. 
Complaint-triggered inspections are also common. 
Unfortunately, determining whether a complaint was about a skimmer installation is difficult.
Complaints unrelated to skimmers can include skimmer checks and the word 
\texttt{skimm} \cite{7690-290206}.
Addtionally, note that the total number of documents is greater than number of parsable PDFs.
This is because some documents contained multiple inspection reports concatinated.

\begin{table}
    \centering
    \begin{tabular}{@{}lcr@{}}
    \toprule
    Origin Header & Meaning                        & Number of Documents \\ \midrule
    SCH           & Regular Scheduled Inspection   & \numSCHOrig \\
    SKI           & Skimmer Inspection Report      & \numSKIOrig \\
    COM           & Complaint Triggered Inspection & \numCOMOrig \\
    REI           & Price Posting Inspection       & \numREIOrig \\ 
    VDA           & Meter Licensing Inspection     & \numVDAOrig \\
    VAN           & Vapor Recovery Inspection      & \numVANOrig \\
    COL           & Licensing Fee Collection       & \numCOLOrig \\
    SPC           & Fuel Quality Inspection        & \numSPCOrig \\ \bottomrule
    \end{tabular}
    \caption{
      Summary of skimmer inspection form data origins and their occurrence rate.
      Reports are submitted most often for scheduled and skimmer-specific inspections.
    }
    \label{tab:explanations-of-origins}
\end{table}


\begin{figure}
    \lstset{language=bash}
    \begin{lstlisting}
      grep -li "skimm" $(grep -li "origin[ :]*\s*com" *.txt)
    \end{lstlisting}
    \caption{
      Example regular expression used to match document types.
      In this case, the script finds complaint triggered reports that mention skimmers.
    }
    \label{fig:grep-code}
\end{figure}

A regular expression was built to extract the origin header the documents
(Figure~\ref{fig:grep-code}).
This excluded~\numNonParsableAZDWMpdfs~from Table
\ref{tab:explanations-of-origins}. 
Most of these documents have missing or incorrect ToUnicode CMaps.
Documents with embedded fonts include this mapping for the extraction of Unicode content
\cite{toUnicode-mapping-tutorial}.
High-quality optical character recognition (OCR) has potential to correct these documents. 
This analysis was attempted and is detailed in Section~\ref{sec:complications-of-ocr}.
\numPressureDecayTest~of the documents did not contain the first, primary report page.
These correspond to Pressure Decay Test forms, used when testing the pumps for leaks.

% The ``pre-inspection checklist", indicating the discovery of a skimmer is usually hand written
% (Figure~\ref{fig:handwritten-checklist}).
% 
% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{pics/handwritten-checklist.png}
%     \caption{
% 	    Example of an inspection report which is not parsable via \texttt{pdftotext}.
%       In this case, even OCR is unable to infer the handwritten text.
%     }

\subsection{Preforming OCR on~\numNonParsableAZDWMpdfs~PDFS}\label{sec:complications-of-ocr}

The OCR to correct the missing ToUnicode CMaps was somewhat effective.
After performing this analysis, the number of unrecognized origin headers dropped to
\amountofparsableoriginsafterocr.
The OCR was performed using \texttt{ocrmypdf} which operatings using the Tesseract library
\cite{smith2007overview}.
The \texttt{-clean} and \texttt{--rotate-pages} flags were used for document cleaning and orientation detection.
The final results table is included in Figure~\ref{tab:final-orig-results}.

\begin{table}
    \centering
    \begin{tabular}{@{}lr@{}}
    \toprule
    Origin Header & Number of Documents \\ \midrule
    SCH           & \finalnumSCHOrig \\
    SKI           & \finalnumSKIOrig \\
    COM           & \finalnumCOMOrig \\
    REI           & \finalnumREIOrig \\ 
    VDA           & \finalnumVDAOrig \\
    VAN           & \finalnumVANOrig \\
    COL           & \finalnumCOLOrig \\
    SPC           & \finalnumSPCOrig \\ \bottomrule
    \end{tabular}
    \caption{
      Summary of skimmer inspection form data origins and their occurrence rate.
      Reports are submitted most often for scheduled and skimmer-specific inspections.
    }
    \label{tab:final-orig-results}
\end{table}

\emph{All} the \numAZDWMpdfs PDFs underwent OCR.
The analysis could have isolated the~\numNonParsableAZDWMpdfs~ unparsable PDFs only.
However, it was unclear whether the entire set of PDFS were non-corrupted. 
Additionally, OCR allowed for parsing the cleanly handwritten reports.
With EC2, this analysis took \ectwohoursspect hours on a 72 core machine. 
The cost was \ectwodollarsspent.

A downside of OCR is that it has trouble inferring the layout of text on the page.
Figure~\ref{fig:misplaced-pdftotext} compares the layout of the original report to it's OCRed duplicate.
This made the generation of regular expressions for content of the page nontrivial.
To solve this problem, I developed a more sophisticated tool for text extraction.
This tool, data-extract-PDF~\cite{dataExtractPdf}, allows the automated extraction of PDF sections.
Unfortunately, this tool was not used for the final analysis in this project.
However, another project with a large number of PDFs is a variant of it for content extraction.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{report_pics/misplaced-pdftotext}
    \caption{
	    Example of a report \texttt{pdftotext} with layout after OCR.
	    \todo{details}
    }
    \label{fig:misplaced-pdftotext}
\end{figure}

\subsubsection{Open Problems in Optical Character Recognition}

Additional work is needed on document content extraction. 
It may be possible to build an inference system which can correct the CMap issues seen in this group of PDFs.
This would a benefit to search engine document indexing and empirical research.
Better document layout recognition would also benefit this research.
Scene text recognition has been a longstanding open problem. 
The first public data set, the ICDAR Robust Reading challenge, was created in 2003 
\cite{lucas2003icdar}. 
However, these data sets focus on images and not on documents.
Recent advances in Visual Question Answering (VQA) could be used for this purpose.
Last year, Anderson presented Bottom-Up and Top-Down attention models.
\cite{anderson2018bottom}.
These models operate at the level of objects and image regions, rather than uniform grids.

\section{Document Data Extraction}\label{sec:document-data-extraction}

Despite parsing difficulties, the documents contain useful information about skimmer investigations.
Of particular interest is the number of skimmer inspections which discover skimmers.
A manual analysis of all the documents would be required to answer this question with perfect precision.
Thus, several alternative approximations were attempted.
Each alternative method and the resulting approximation are detailed in Table
\ref{tab:success-rates}.
Details about these methods are included in the next three sections.
The AZDWM was also contacted directly for the ground truth data. 
Their reported ``hit" rate for unhinted inspections was 
\percentSkimmersToStations.

\begin{table}
    \centering
    \begin{tabular}{lcr}
    \hline
    Approximation Method  & Number of Documents Reported & Approximated Unhinted Success Rate \\ \hline
    Keyword Analysis      &                              &                                    \\
    Phrase-based Analysis &                              &                                    \\
    Random Sampling       &                              &                                    \\ \hline
    \end{tabular}
    \caption{The various skimmer detection success rates as reported by different methods for document analysis. \todo{details}}
    \label{tab:success-rates}
\end{table}

    \subsection{Keyword-based Analysis}

    The first attempt at skimmer detection rate estimation was keyword based.
The intuition was to subtract the reports with the words ``no skimm" from the reports with the word ``skimm". 
This number deviates from the ground truth for trivial reasons. 
For one, the pre-inspection checklist includes the term ``skimm". 
The reported skimmer detection success rate based upon this metric was \skimmerwordbasedsuccessrate.
The actual detection rate for unhinted inspections is much lower. 
Using a keyword search misses semantic details of the content. 
For instance, the skimmer may have been discovered before AZDWM was called.

    \subsection{Phrase-based Analysis}

A phrase-based approach was also evaluated. 
The corpus of phrases is included in Table~\ref{tab:phrase-corpus}.
To build this table, the documents were randomly sampled and manually analyzed.
More complex signifiers allowed for the preservation of more semantic content.
In this case, the percentage discovery rate reported by this technique was~\phrasebasedsuccessrate. 
This is closer to the the ground truth reported by the AZDWM. However, it still suffers many of the same drawbacks as the keyword based approach.

\begin{table}
    \centering
    \input{tabs/phrase-corpus}
    \caption{The corpus of phrases used to determine whether a skimmer was found. \todo{details}} 
    \label{tab:phrase-corpus}
\end{table}

This method was effective because a small number of investigators generated the reports.
The phrases captured the individual idiosyncrasies of investigators. 
Each inspector will, for a time, have ``their way" of signifying whether they found a skimmer or not.
However, phrase based analysis remains inaccurate. 
The are many subtle indicator phrases that an inspection was not random. 
Some of these, such as ``owner found skimmer", can be captured.
Others are report-specific and cannot be included without manual analysis of every document.
This makes it difficult to determine whether the phrase corpus is unbiased.

\subsection{Random Sampling}

The next method attempted was random sampling. 
This determined a skimmer detection success rate of \randomsamplesuccessrate
($\sigma = \randomsamplestdev$).
Manual analysis of the sampled documents allowed the removal of hinted reports.
This approach also won out in the time taken to perform the analysis. 
Collecting a reasonable corpus for the phrase-based analysis took more time. 
These approaches show different prediction convergence behavior as time progresses.
Random sampling ``zeroes in" on a mean estimate, while phrase-based analysis moves step-wise. 
The latter of the two is only rigorous under restricted circumstances.
Figures \ref{fig:phrase-based-accuracy-num-terms} and \ref{fig:random-sampling-accuracy-num-reviewed} provide this comparison. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{plots/phrase-based-accuracy-num-terms}
    \caption{
	    The reported number of skimmer detection success rate as reported by the phrase-based model
	    as the number of terms increased.
	    \todo{details}
    }
    \label{fig:phrase-based-accuracy-num-terms}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{plots/random-sampling-accuracy-num-reviewed}
    \caption{
	    The convergence of the success rate inferred by random sampling as the number of 
	    documents sampled increases.
	    \todo{details}
    }
    \label{fig:random-sampling-accuracy-num-reviewed}
\end{figure}

These findings show the inadequacy of naive automated approaches in empirical study.
These approaches can be tempting in their formality.
However, in some domains, they do not provide a rigorous enough analysis. 
Manual inspection can also contain biases, but evaluating this can be difficult.
In this study, the accuracy of random sampling suggests inspection bias was not an issue.

\section{Addressing Biased and Noisy Data}

In attempting to disambiguate whether an inspection was performed or not, it became apparent through  our sampling of the data that the inspections themselves were biased.
Often, the inspection notes indicated that the inspection was triggered on a hint from a local police department, a service tech, or gas station owners (Figure~\ref{fig:hinted-report}).

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{report_pics/hinted-report}
    \caption{
	    The reported number of skimmer detection success rate as reported by the phrase-based model
	    as the number of terms increased.
	    \todo{details}
    }
    \label{fig:phrase-based-accuracy-num-terms}
\end{figure}

We also discovered that there was no linear separability between report types: SKIs and COMs are both triggered by complaints.
The reference documents in Figure~\ref{fig:non-linear-seperability} demonstrate this lack of linear seperability.
Additionally, it is unclear from the documents themselves whether a skimmer inspection was actually performed, although one may have been.
Some reports indicated that there was a pre-inspection checklist including a skimmer investigation, however, not all reports included this.

To answer this question, we contacted AZDWM, who indicated that a skimmer inspection was performed any time the pumps were opened.
However, was this may have been impossible to infer from the reports themselves.
Thus, we performed a seperate analysis which could also determine the rate of skimmer inspections influenced by signal processing.
We looked at the incidence of skimmer discovery for each inspector based upon the documents classified during direct manual analysis (perhaps one benefit of manual analysis when compared to random sampling).
The results are recorded in Figure~\ref{fig:skim-discover-rate-per-inspect}.
This gave us an idea of the baseline skimmer discovery rate per day for each inspector, and allowed us to classify occurrences which may have been biased by a hint, as well as get an idea for how many reports were filed for each inspector.
Overall, these findings demonstrate that the obvious statistics may not reveal the underlying character of a dataset, whereas tertiary measurements of the system can still provide indicators of underlying causal mechanisms.

Additionally, random sampling could be performed to determine which proportion of documents were hinted.
For the proportion of reports that found skimmers, we found that \randsamplehinted of the reports were hinted, with a standard deviation of \randsamplehintedstddev.
Since the standard deviation was so small, it is fair to multiply this by the success rate in determining the total unhinted skimmer success rate as somewhere around \randsampleultimatesuccess.
This ended up close to the actual AZDWM reported success rate.

    \section{Describing Inspections and Skimmers}\label{sec:describing-inspections-skimmers}

    \subsection{Inspector Behavior}\label{sec:inspector-behavior}

    The method adopted for understanding the human factors involved in skimming investigations was also based upon the methods highlighted above.
    However, the amount of information contained in randomly sampled reports on inspector behavior was sparse: it was found that among  \numrandominspbehav randomly chosen documents, only \numinforandinspbehav had legitimate information on how the inspection was preformed, and only \numrandinspbehavskim mentioned skimmers.
    This could be improved upon using two heuristic methods: the first being the number of words in the inspection document, with the distribution of word counts over all the PDFs demonstrated in Figure~\ref{fig:word-distribution-all-pdfs}.
    The second is searching for the ``skimm'' keyword.
    The counts for each of these methods in information recovery are described in Table~\ref{tab:inspbehavnums}.

    It is possible that even more sophisticated methods than word count could have been used, such as the number of legitimate english sentences or English trigrams.

    During this manual analysis, several interesting findings about skimmer inspections were found...

    We know they don't check if they dont need to, but do sometimes if they are instructed to, and sometimes they don't check when they should.
    Tape, locks, alarms. We find in the reports that inspectors oftentimes will not check pumps if there are security seals, special keys, alarms, or ``non-skimmable'' pump types.  Some methodologies of inspection are sound, others are not.  A few reports mention only checking for external skimmers, completely ignoring the internal variety. 
    
    \subsection{Skimmer Construction}\label{sec:skimmer-construction}

    Additionally, this analysis led to an increased understanding of skimmer construction ...

    Many of the reports noted that the skimmers were bluetooth

    From photos of the modules, we were able to infer the manufacturer, and use this to build and initial list of questionable OUIs.

    We note that criminals need some way to exfiltrate the data, and Bluetooth is cheap.

    Necessary checklists also note that GSM skimmers are possible.

    Some potential MAC addresses were noted in reports, but these claims were later shown to be non-instantiable.

    \subsection{Inspection Time Analysis}\label{sec:insp-time-ana}
    
    Taking the lessons learned from the previous section, we continued to perform random sampling analysis of the rest of the documents.
    This gave us key insights  into the inspection time distribution of inspectors.
    Many inspection times were handwritten and the OCR algorithm was not able to infer the times written (\nonparsableinspectiontimes).

    The distribution of inspection times as reported by documents that were classified as having performed skimmer inspections is included in \ref{fig:time-dist-plot}.

    \subsection{Biased Inspection Frequency}

    During this analysis, there was the hypothesis that inspectors were biased towards certain stations when looking for skimmers ...

    - Plots of number of inspections a given gas station gets in a period of time

    \section{Errors}

    The false claims of some reports indicate the traditional notion of flawed authorial perspective.
    In general, however, there will always be errors, which indicates that even amongst these heuristic classifications of inspector behavior, one must be careful not to generalize.
    Different inspectors write reports and perform inspections in different ways, but if each of these manners is classified for each inspector, then oddities may be ironed out.
    This is the type of analysis error that depends on the data set.

    Other errors may be quantified.
    For instance \numdocumentsinspunclassifiable reports were not classifiable as a skimmer or non-skimmer inspection.
    It is also the case, such as in \url{rep}, that it is unclear the exact steps the inspector used to inspect, although they found skimmers.
    Based upon exploratory data analysis, however, you can make compelling arguments that some data is non-attainable.

    - Always will be errors. The law of large numbers assumes these smooth out in a large
    enough sample size
    - Plots of the data which is unclassified
    - Plots of the types of inspections
    - Looking at whether inspectors actually inspect

    Different inspectors write reports in different ways, but these number of ways becomes constant in a larger dataset.
    Could use machine learnign to learn one inspector's style, there will be oddities, yada...

    We can leverage the fact that these inspectors are going to thousands of gas stations and manually inspecting the pumps in order to get data on the nature of skimmers, and help to find a few.

    \section{Lessons Learned}

    The lesson learned: to solve a problem, test your target population.

    As inspectors collect data, Bluetana can learn new features and attempt more ways of finding skimmers.

    As criminals adapt, WM staff will still be the ones going to stations. This would actually make the deployment of a persistent solution not too hard.

    Looking for documents that have a new formal structure: information in the document class, rather than input.
    - Look for word overlap in the document pages, classify by levenstien distance

    \section{The Design of Bluetana}

    Working from the data covered in this section, one can begin to develop ideas for potential solutions to the skimming problem.  The next chapter will discuss the design of an application, Bluetana, which serves to passively and actively detect skimmers, allowing inspectors to more easily check the pumps and avoid errors.  These reports also indicate other avenues for solving the skimmer problem, such as persistent devices or training for gas station employees on signs of tampering. 

    \section{Related and Future Work}

    In this chapter, both keyword and phrase-based analysis were inaccurate in semantic classification.
    Random sampling was closer in determining the success rate of skimmer investigations.
    These same techniques were used to understand skimmer construction and investigator behavior.
    Since the documents are rich text by investigators, manual analysis was still needed to answer questions such as "Do inspectors check pumps with security seals?".
    A system for answering these queries would reduce the need for manual analysis.
    Similar tasks are already performed by the content-based filtering of recommendation systems.
    The classic content-based recommender system uses word frequency and a user profile (e.g. demographics) \cite{pazzani1999framework}.
    A query could take the place of a user profile.
    However, this approach requires a semantic understanding of the document and the query.
    A 2011 survey by Lops notes several approaches for representing this semantic information.
    An example would be weighting documents by the frequency of rare terms \cite{lops2011content}.
    However, at the time of writing, a system for performing the analyses presented by Lops in a free, quick, and automated manner does not seem to exist.
    In our case, Mechanical Turk or a trained ANN may have been enough to answer most questions.
    However, answering each question would have required a separate round of testing or training.

\section{Summary}
\section{Acknowledgements}

