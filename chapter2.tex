\chapter{Understanding Field Agent Behavior}\label{chap:2}
\begin{quote}
    ``It is a capital mistake to theorize before one has data.'' \\
    --- Sir Arthur Conan Doyle, \emph{Sherlock Holmes}
  \end{quote}

This chapter surveys gas pump inspection reports from the Arizona Department of Weights and Measures (AZDWM). It begins by attempting to attain descriptive statistics related to skimming from these documents. Challenges in attaining these statistics lead into discussion of data acquisition methodologies. This chapter then highlights discoveries about inspections and skimmers contained within the documents. It concludes with a summary of the motivation for Bluetana's development provided by the documents and future work. 

Analysis of the data provided by AZDWM proved to be difficult, but had two primary benefits. The first was a categorical understanding of current investigative techniques: notes provided by investigators offer insight into how they perform inspections. The second was an understanding of the potential avenues of skimmer detection. Photos and forms included in the reports reveal details of skimmer construction. These details suggest Bluetooth modules are commonly used and that Bluetooth is a potentially effective route for detection. 

Finally, This chapter functions as a \emph{case study} of exploratory data analysis. It does not provide universal techniques; instead, it compares multiple approaches to the analysis of gas station inspection documents. This structure allows the chapter to demonstrate some ways \emph{not} to do data analysis on this type of data set. It does so by comparing tempting, flawed data analysis techniques to ground-truth data. 
    
    \section{Survey Background}

Inspection report PDFs from the AZDWM are accessible through a queriable web interface (\url{https://ctutools.azda.gov/PdfOriginals/}). Thus, the data set of reports was retrieved via an html parser and batched \texttt{wget} requests. The PDFs downloaded from this source include documents unrelated to inspections. PDFs relating to inspection reports follow a naming scheme of \texttt{\{BMF \#\}-\{Inspection \#\}.(pdf|PDF)}. A BMF, or Business Master File, number is a unique identifier given to each business by the AZDWM \cite{azdwmLicensing}. It is not clear from the filenames which reports pertain to skimming.  Thus, classifying and analyzing these reports requires parsing the PDFs themselves. Luckily, reports contain a header that indicates the origin of the inspection.

    There are~\totalAZDWMpdfs~inspection report PDFs available on the AZDWM website. The oldest report available is from July 2010. This survey will focus on reports filed from the beginning of 2016 to the end of 2018. This amounts to a total of~\upperAZDWMpdfs~reports. By restricting analysis to the past three years of data, we preserve the relevance of the study to the present day. Table~\ref{tab:overview-azdwm-stats} provides overview statistics on the documents. 

\begin{table}
    \centering
    \noindent
    \begin{tabular}{l|c}
    \toprule
    Total Number of Documents                                         & \upperAZDWMpdfs  \\
    \midrule
    Number of Documents with Parsable Origin                          & \numParsableAZDWMpdfs   \\
    \midrule
    Number of Documents Originating from a Skimmer Inspection         & \numSKIorigin  \\
    \midrule
    Number of Documents Matching the Regular Expression ``[Ss]kimm''  & \numSkimWord  \\
    \midrule
    Success Rate Reported by the AZDWM (Unhinted)                     & 1.5\%  \\
    \bottomrule
    \end{tabular}
    \caption{Overview statistics on the documents from AZDWM gas station inspection reports. Only a portion of the documents are parsable. Some non-skimmer inspections include checks for skimmers.}
    \label{tab:overview-azdwm-stats}
\end{table}

A primary goal of this survey is to understand how investigators perform skimmer inspections. For instance, how rigorously inspectors investigate pumps (Section~\ref{sec:inspector-behavior}). Another goal was to quantify the hit rate of skimmer inspections (Section~\ref{sec:document-data-extraction}); this provides a measure of how common skimming is. Additionally, it was important to determine how much room for improvement there is in detection methods. This was done by measuring how long inspections take to complete (Section~\ref{sec:insp-time-ana}). 

\section{Understanding the Documents}\label{sec:understanding-the-documents}

      Upon examining the PDFs, we find the information contained within is highly unstructured. For example, the documents have an inconsistent use of the 198 failure code. This code indicates a skimmer was found. Figure~\ref{fig:198-usages} depicts two different uses of this code. There also exist successful skimmer inspections with no 198 code in the document at all \cite{13529-268466}. Unfortunately, this indicates a single regular expression search for successful investigations is nontrivial. Additionally, there are latent ambiguities in the data collected. Many documents do not state whether a found skimmer was internal or external. They also do not indicate whether a given inspection called in by a gas station owner or other party. This would be the case if the station owner or service tech was responsible for the discovery of the skimmer.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/198-usages.png}
    \caption{
      Inconsistent use of the 198 error code. In the top report, the code is included in the inspection notes. In the bottom image, a separate field used for fail codes contains the 198.
    }
    \label{fig:198-usages}
\end{figure}

The exact skimmer inspection methodology is not noted in any of the reports. There are, however, hints within the inspection notes and the document structure. For instance, vapor recovery\footnote{Checking the pumps to make sure they do not leak gasoline vapors into the atmosphere.}  reports contain a pre-inspection checklist. This checklist contains a check for skimmers (Figure~\ref{fig:check-for-skimmers}). The reports do not contain information on the whether skimmer investigations occur alongside other inspections; however, the AZDWM site notes skimmer inspections are always performed during pump inspections \cite{azdwmSkimmers}. Thus, any report that includes a pump inspection includes a skimmer check.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/inspection-checklist.png}
    \caption{
	    Section of the inspection reports which demonstrates information on the pre-inspection checklist. In this case, no skimmer was found.
    }
    \label{fig:check-for-skimmers}
\end{figure}

The inspection reports also contain information on skimmer construction.
Some report forms have a checkbox for tagging whether a skimmer is SMS or Bluetooth enabled
(Figure~\ref{fig:bluetooth-or-gsm}).
However, inspectors may not have a perfect sense of this.
AZDWM has informed us Investigators do not to remove any tape used to encase or hide the skimmer in the pump.
This is done to preserve fingerprints 
\cite{20340-269297}.
Some documents do attempt to correlate Bluetooth features to discovered skimmers. 
For example, MAC addresses and skimmer names
(Figures~\ref{fig:mac-address-report}).
During the Bluetana study, these hints were found to be inaccurate.
However, they do illustrate some investigator awareness of Skimmers' Bluetooth capabilities.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/bluetooth-or-gsm.png}
    \caption{
      Some inspection forms include a checkbox for the exfiltration mechanism of the skimmer.
      While the selection of SMS may not be accurate, it does indicate not all skimmers use Bluetooth.
    }
    \label{fig:bluetooth-or-gsm}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/mac-address-report.png}
    \caption{
	    Section of the inspection reports noting a potential MAC address for a skimmer.
      Follow up investigation found this MAC address to be uncorrelated with skimmer discovery.
    }
    \label{fig:mac-address-report}
\end{figure}

    \subsection{Understanding Document Origins}

Inspection reports have~\numorigins~different origin headers.
Table \ref{tab:explanations-of-origins}
contains statistics and descriptions of the different report types.
No online resource explains what these headers mean.
Thus, the explanations included are from manual analysis. 
Regular, scheduled inspections are the most common, followed by skimmer inspections. 
Complaint-triggered inspections are also common. 
Unfortunately, determining whether a complaint was about a skimmer installation is difficult.
Complaints unrelated to skimmers can include skimmer checks and a regular expression match for 
\texttt{[Ss]kimm} \cite{7690-290206}.

\begin{table}
    \centering
    \begin{tabular}{@{}lcr@{}}
    \toprule
    Origin Header & Meaning                        & Number of Documents \\ \midrule
    SCH           & Regular Scheduled Inspection   & 10,670              \\
    COM           & Complaint Triggered Inspection & 1,692               \\
    VDA           & Meter Licensing Inspection     & 377                 \\
    SKI           & Skimmer Inspection Report      & 2288                \\
    SPC           & Fuel Quality Inspection        & 43                  \\
    COL           & Licensing Fee Collection       & 168                 \\
    VAN           & Vapor Recovery Inspection      & 352                 \\
    REI           & Price Posting Inspection       & 768                 \\ \bottomrule
    \end{tabular}
    \caption{
      Summary of skimmer inspection form data origins and their occurrence rate.
      Reports are submitted most often for scheduled and skimmer-specific inspections.
    }
    \label{tab:explanations-of-origins}
\end{table}


\begin{figure}
    \lstset{language=bash}
    \begin{lstlisting}
      grep "[Ss]kimm" $(grep -l "[Oo]rigin[ :] *COM" *.txt)
    \end{lstlisting}
    \caption{
      Example regular expression used to match document types.
      In this case, the script finds complaint triggered reports that mention skimmers.
      }
    \label{fig:grep-code}
\end{figure}

A regular expression was built to extract the origin header the documents
(Figure~\ref{fig:grep-code}).
This excluded~\numNonParsableAZDWMpdfs~from Table
\ref{tab:explanations-of-origins}. 
\texttt{pdftotext}, used for the generation of parsable text, had failed on these documents. 
Many of these documents were ``pressure decay test" forms, that do not include a skimmer check.
Others did not contain the first, primary report page. 
This makes regular expression based origin determination difficult or, in some cases, impossible. 
Others were of poor PDF quality, hand written, or photos of the report form, such as in Figure
\ref{fig:photo-of-report-form}.
This presented three further options for analysis. 

\begin{itemize}
\item 
A more sophisticated regular expression could capture a greater proportion of the documents.
This was attempted and found to be difficult and inadequate in characterization
\item
These non-parsable documents could be discarded.
However, these PDFs accounted for~\percentNonParsableAZDWMpdfs~and presented potential for a biased analysis. 
\item
The performance of high-quality optical character recognition could correct the PDF text inference. 
Since there was no downside to this approach, it was attempted. The next section details the efficacy of this computationally-heavy analysis.
\end{itemize} 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/photo-of-report-form}
    \caption{
	    Example of a report which would not be parsable directly via \texttt{pdftotext}.
    }
    \label{fig:photo-of-report-form}
\end{figure}

    A case analysis of the initial set of PDFs led to the characterization presented in Table~\ref{tab:num-failed-regex-ocr} when examining the origin header.  The table is broken down by year for sake of characterizing AZDWM behavior over time.  We can see that there was a clear transition around \yearofhandwrittentotyped of handwritten to typed reports.  At this point, a judgment must be made as to whether additional effort should be spent to analyze these additional documents.

\begin{table}
    \centering
    \input{tabs/num-failed-regex-ocr}
    \caption{Summary counts for the origin headers parsable without OCR and with OCR. \todo{details}} 
    \label{tab:num-failed-regex-ocr}
\end{table}

    \subsection{Complications of OCR}

    If the purpose is complete understanding of the exact statistics of the data set, a mixture of FSMA will be needed to complete the analysis.  One mistake of this study was to not properly understand and segment the data which needed additional time to process: the choice was blindly made to perform OCR on all the documents, leading to \ectwohoursspent hours of Amazon EC2 time spent on a 72 core machine, a monetary cost of \ectwodollarsspent.

    The OCR was somewhat effective; after performing this analysis, the number of documents with an unrecognized origin header dropped \amountofparsableoriginsafterocr.  The OCR was performed using the tool \texttt{ocrmypdf}, which builds upon the Tesseract library.  Despite these final statistics, our initial OCR run did not improve the number of parsed origin headers as much as inspected.  It was later found that additional flags were needed for document cleaning and orientation detection\footnote{\texttt{-clean} and \texttt{--rotate-pages} respectively.}.  This additional run of OCR wasted time and led to a short period of insecurity relating to the ability to parse the data in an automated fashion.  It is important to understand \emph{all} the features of the tools used for data extraction when performing analysis and the number of errors is outside of desired bounds.  In fact, it is possible that adding additional flags to Tesseract's OCR may have made the data analysis far more accurate.  Additionally, this analysis demonstrates the importance of knowing when FSMA is failing, so steps may be taken to prevent wasting time and inaccuracies.  Finally, OCR was performed, inefficiently, on \emph{all} the documents: this was a complete mistake, and a result of not doing proper exploratory data analysis beforehand as a result of a lack of time.  Ideally, the information provided in Table~\ref{tab:num-failed-regex-ocr} would have been used to shrink the amount of time, effort, and money required to perform optical character recognition on these documents. 

    A primary challenge of performing OCR on the documents was layout inference of text within the documents; the inference of the line position to approximate visual position is highly inaccurate.  Figures~\ref{fig:misplaced-pdftotext} and \ref{fig:messy-regex} display the improper text positioning inferred by pdftotext for a document and an abandoned regular expression used for parsing text positioning before a more sophisticated method was attempted.  

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{report_pics/misplaced-pdftotext}
    \caption{
	    Example of a report \texttt{pdftotext} with layout after OCR.
	    \todo{details}
    }
    \label{fig:misplaced-pdftotext}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pics/messy-regex}
    \caption{
	    Example of a regex used to attempt to handle all variations in document structure.
	    \todo{details}
    }
    \label{fig:messy-regex}
\end{figure}

    In order to counteract difficulties in the organization of raw text data from the output of pdftotext, I built a tool, code-named data-extract-PDF \cite{dataExtractPdf}.  This tool allows the user to select sections of PDFs in an automated manner and ``snip'' them out of the document, or otherwise develop toolkits for automated data entry and extraction.  This tool has proved to be quite useful, and is now being used in two other research projects I am undertaking involving document snippet extraction.

    \subsubsection{Open Problems in Optical Character Recognition}

    Additional work is needed on semantic text recognition systems which directly work with a human user in the performance of document classification.  This could serve to further the cause of empirical research not only in the field of computer science, but in many other industries and in other areas, such as literary theory, biology, and even mathematics.  From the phrase-based analysis, we found that approaches based upon part-of-speech tagging, which look for key uses of semantic information constructs could provide the basis for such natural language processing applications.  Additionally, mechanisms are needed for the inference of missing data from optically read documents, and this is the subject of other research which I am in the process of performing.  Difficulties were also encountered in the OCR system's ability to group sections of text semantically, in terms of boxed content on the page seperated by vertical lines.  Small changes in the understanding that the system provides could improve the inference power of these systems significantly.


    \section{Document Data Extraction}\label{sec:document-data-extraction}

    With the data extracted from the documents, one can learn several interesting and useful facts about the behavior of inspectors and the nature of skimmers.  Primary among these facts is the number of successful inspections for skimmers of different origin types.  Figuring out just one piece of evidence from these documents proves to be difficult, and thus I dedicate the next few sections to the nature of the analysis, in hopes that it will be instructive for future work.  For the final work \cite{bhaskar2019pay}, we ended up getting ground truth data of skimmer detection accuracy from Arizona.  This provides an opportunity for a comparison of the attempted data analysis techniques.

    Before it is possible to analyze success rate, we must figure out whether or not an inspection occurred for a skimmer.  In order to do so, we explore several different techniques:

    \begin{itemize}
    \item Reports with the word skimmer in them.
    \item Reports with a combination of phrases in them constructed from a sampling of reports.
    \item Random sampling by hand.
    \item Manual inspection of reports by hand.
    \end{itemize}

    These techniques were usable after the unclean documents had OCR performed upon them.  However, they had differing levels of success.  We contacted AZDWM directly in order to get accurate statistics for the number of skimmers found during routine investigations and found that the success rate for these investigators was~\azgivenskimsuccessrate.  The comparable statistics recovered from each of these methodologies are detailed in Table \ref{tab:success-rates}.

\begin{table}
    \centering
    \input{tabs/success-rates}
    \caption{The various skimmer detection success rates as reported by different methods for document analysis. \todo{details}} 
    \label{tab:success-rates}
\end{table}

    \subsection{Skimmer word included}

    The first attempted method for determining the success rate of skimmer investigations was simply to find reports that had the word ``skimm'' in them and reports which had the words ``no skimm'' in them.  Understandably, this is a highly flawed number, and so we expect the results to be highly deviated from the actual reports of the AZDWM.  Thus, this serves as a straw-man case for the more general technique of phrase-based refinements for NLP statistical mining.  The reported skimmer detection success rate based upon this metric was \skimmerwordbasedsuccessrate.  One limitation of this approach could be that the reports were not linearly differentiable by the simplest word cases alone.  Thus, this approach was extended to a phrase-based analysis.

    \subsection{Phrase-based analysis}

    The phrase-based analysis followed from a sampling of many of the reports which allowed the determination of common phrases used by investigators indicating that a skimmer was found and a skimmer was not found.  The percentage success rate reported by this technique was~\phrasebasedsuccessrate~, which is closer to the ground truth reported by the Arizona department of weights and measures.  The corpus of phrases is included in Table~\ref{tab:phrase-corpus}.

\begin{table}
    \centering
    \input{tabs/phrase-corpus}
    \caption{The corpus of phrases used to determine whether a skimmer was found. \todo{details}} 
    \label{tab:phrase-corpus}
\end{table}

    This method proved to be effective given the small number of inspectors in the AZDWM during this time period, which provided some consistency to the results for inspection success rate.  However, it is not clear that this form of modeling would generalize to the entire human population.  In fact, this form of case-based analysis is what led to a plateau in artificial intelligence research in the late 80's and early 90's \cite{norvig2012artificial}.  Thus, I also attempted to evaluate the accuracy of random sampling in data analysis.

    \subsection{Random Sampling}

    The next method attempted was random sampling which portrayed a skimmer detection success rate of \randomsamplesuccessrate.  This had a modest standard deviation of \randomsamplestddev, which was within the range of the reported AZDWM numbers to very low error.  Random sampling, therefore, proved to be highly accurate, and in the end, required less time than comparative phrase-based analysis.  Developing a corpora of common phrases is a highly manual task, as was analyzing random samples of the documents.  However, developing the corpora presented above required going through many, many documents.  Unfortunately, data was not collected on the accuracy of the model over time, though Figure~\ref{fig:phrase-based-accuracy-num-terms} gives a measure of the accuracy as phrases were added.  Comparatively, Figure~\ref{fig:random-sampling-accuracy-num-reviewed} gives a measure of the accuracy of the estimate, with standard error, for each document reviewed. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{plots/phrase-based-accuracy-num-terms}
    \caption{
	    The reported number of skimmer detection success rate as reported by the phrase-based model
	    as the number of terms increased.
	    \todo{details}
    }
    \label{fig:phrase-based-accuracy-num-terms}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{plots/random-sampling-accuracy-num-reviewed}
    \caption{
	    The convergence of the success rate inferred by random sampling as the number of 
	    documents sampled increases.
	    \todo{details}
    }
    \label{fig:random-sampling-accuracy-num-reviewed}
\end{figure}

    We can see that random sampling is a sound scientific method for document analysis, and the general intuition regarding its efficacy in data analysis is most likely correct.  While other methodologies may be tempting, the author would strongly discourage these other techniques, as they may create bias in the results attained by studies.  However, random sampling with manual analysis is also biased by the observer classifying the samples.  Thus, we also look at the efficacy of total manual inspection of roughly half of the AZDWM reports.

    \subsection{Manual Inspection}

    Finally, there was a time during which manual inspection was used in order to determine the success rate of skimmer investigations.  Unfortunately, this was abandoned halfway due to the monotony of classifying skimmer inspection documents and the time required.  However,~\manualinspectionnumber~documents were still classified, and constituted a semi-random sample of the entire corpus of documents, including all reports from 2016 onward.  The ultimate success rate reported was \manualinspsuccessrate, which is close to the AZDWM reported number.  Thus, manual inspection is accurate, but remains an ineffective manner of exploratory data analysis.

    \section{Addressing Biased and Noisy Data}

    In attempting to disambiguate whether an inspection was performed or not, it became apparent through  our sampling of the data that the inspections themselves were biased.  Often, the inspection notes indicated that the inspection was triggered on a hint from a local police department, a service tech, or gas station owners (Figure~\ref{fig:hinted-report}).

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{report_pics/hinted-report}
    \caption{
	    The reported number of skimmer detection success rate as reported by the phrase-based model
	    as the number of terms increased.
	    \todo{details}
    }
    \label{fig:phrase-based-accuracy-num-terms}
\end{figure}

    We also discovered that there was no linear separability between report types: SKIs and COMs are both triggered by complaints.  The reference documents in Figure~\ref{fig:non-linear-seperability} demonstrate this lack of linear seperability.  Additionally, it is unclear from the documents themselves whether a skimmer inspection was actually performed, although one may have been.  Some reports indicated that there was a pre-inspection checklist including a skimmer investigation, however, not all reports included this.

    To answer this question, we contacted AZDWM, who indicated that a skimmer inspection was performed any time the pumps were opened. However, was this may have been impossible to infer from the reports themselves.  Thus, we performed a seperate analysis which could also determine the rate of skimmer inspections influenced by signal processing. We looked at the incidence of skimmer discovery for each inspector based upon the documents classified during direct manual analysis (perhaps one benefit of manual analysis when compared to random sampling). The results are recorded in Figure~\ref{fig:skim-discover-rate-per-inspect}. This gave us an idea of the baseline skimmer discovery rate per day for each inspector, and allowed us to classify occurrences which may have been biased by a hint, as well as get an idea for how many reports were filed for each inspector. Overall, these findings demonstrate that the obvious statistics may not reveal the underlying character of a dataset, whereas tertiary measurements of the system can still provide indicators of underlying causal mechanisms.

    Additionally, random sampling could be performed to determine which proportion of documents were hinted.  For the proportion of reports that found skimmers, we found that \randsamplehinted of the reports were hinted, with a standard deviation of \randsamplehintedstddev.  Since the standard deviation was so small, it is fair to multiply this by the success rate in determining the total unhinted skimmer success rate as somewhere around \randsampleultimatesuccess.  This ended up incredibly close to the actual AZDWM reported success rate.

    \section{Describing Inspections and Skimmers}\label{sec:describing-inspections-skimmers}

    \subsection{Inspector Behavior}\label{sec:inspector-behavior}

    The method adopted for understanding the human factors involved in skimming investigations was also based upon the methods highlighted above.  However, the amount of information contained in randomly sampled reports on inspector behavior was sparse: it was found that among  \numrandominspbehav randomly chosen documents, only \numinforandinspbehav had legitimate information on how the inspection was preformed, and only \numrandinspbehavskim mentioned skimmers.  This could be improved upon using two heuristic methods: the first being the number of words in the inspection document, with the distribution of word counts over all the PDFs demonstrated in Figure~\ref{fig:word-distribution-all-pdfs}.  The second is searching for the ``skimm'' keyword.  The counts for each of these methods in information recovery are described in Table~\ref{tab:inspbehavnums}.

    It is possible that even more sophisticated methods than word count could have been used, such as the number of legitimate english sentences or English trigrams.

    During this manual analysis, several interesting findings about skimmer inspections were found...

    We know they don't check if they dont need to, but do sometimes if they are instructed to, and sometimes they don't check when they should.
    Tape, locks, alarms. We find in the reports that inspectors oftentimes will not check pumps if there are security seals, special keys, alarms, or ``non-skimmable'' pump types.  Some methodologies of inspection are sound, others are not.  A few reports mention only checking for external skimmers, completely ignoring the internal variety. 
    
    \subsection{Skimmer Construction}\label{sec:skimmer-construction}

    Additionally, this analysis led to an increased understanding of skimmer construction ...

    Many of the reports noted that the skimmers were bluetooth

    From photos of the modules, we were able to infer the manufacturer, and use this to build and initial list of questionable OUIs.

    We note that criminals need some way to exfiltrate the data, and Bluetooth is cheap.

    Necessary checklists also note that GSM skimmers are possible.

    Some potential MAC addresses were noted in reports, but these claims were later shown to be non-instantiable.

    \subsection{Inspector Behavior}

    The method adopted for understanding the human factors involved in skimming investigations was also based upon the methods highlighted above.  However, the amount of information contained in randomly sampled reports on inspector behavior was sparse: it was found that amongst \numrandominspbehav randomly chosen documents, only \numinforandinspbehav had legitimate information on how the inspection was preformed, and only \numrandinspbehavskim mentioned skimmers.  This could be improved upon using two heuristic methods: the first being the number of words in the inspection document, with the distribution of word counts over all the PDFs demonstrated in Figure~\ref{fig:word-distribution-all-pdfs}.  The second is searching for the ``skimm'' keyword.  The counts for each of these methods in information recovery are described in Table~\ref{tab:inspbehavnums}.

    It is possible that even more sophisticated methods than word count could have been used, such as the number of legitimate english sentences or English trigrams.

    During this manual analysis, several interesting findings about skimmer inspections were found...

    We know they don't check if they dont need to, but do sometimes if they are instructed to, and sometimes they don't check when they should.
    
    \subsection{Skimmer Construction}

    Additionally, this analysis led to an increased understanding of skimmer construction ...

    Many of the reports noted that the skimmers were bluetooth

    From photos of the modules, we were able to infer the manufacturer, and use this to build and initial list of questionable OUIs.

    We note that criminals need some way to exfiltrate the data, and Bluetooth is cheap.

    Necessary checklists also note that GSM skimmers are possible.

    Some potential MAC addresses were noted in reports, but these claims were later shown to be non-instantiable.


    \subsection{Inspection Time Analysis}\label{sec:insp-time-ana}
    
    Taking the lessons learned from the previous section, we continued to perform random sampling analysis of the rest of the documents.  This gave us key insights  into the inspection time distribution of inspectors.  Many inspection times were handwritten and the OCR algorithm was not able to infer the times written (\nonparsableinspectiontimes).

    The distribution of inspection times as reported by documents that were classified as having performed skimmer inspections is included in \ref{fig:time-dist-plot}.

    \subsection{Biased Inspection Frequency}

    During this analysis, there was the hypothesis that inspectors were biased towards certain stations when looking for skimmers ...

    - Plots of number of inspections a given gas station gets in a period of time

    \section{Errors}

    The false claims of some reports indicate the traditional notion of flawed authorial perspective.  In general, however, there will always be errors, which indicates that even amongst these heuristic classifications of inspector behavior, one must be careful not to generalize.  Different inspectors write reports and perform inspections in different ways, but if each of these manners is classified for each inspector, then oddities may be ironed out.  This is the type of analysis error that depends on the data set. 

    Other errors may be quantified.  For instance \numdocumentsinspunclassifiable reports were not classifiable as a skimmer or non-skimmer inspection.  It is also the case, such as in \url{rep}, that it is unclear the exact steps the inspector used to inspect, although they found skimmers.  Based upon exploratory data analysis, however, you can make compelling arguments that some data is non-attainable.

    - Always will be errors. The law of large numbers assumes these smooth out in a large
    enough sample size
    - Plots of the data which is unclassified
    - Plots of the types of inspections
    - Looking at whether inspectors actually inspect

    Different inspectors write reports in different ways, but these number of ways becomes constant in a larger dataset. Could use machine learnign to learn one inspector's style, there will be oddities, yada...

    We can leverage the fact that these inspectors are going to thousands of gas stations and manually inspecting the pumps in order to get data on the nature of skimmers, and help to find a few.

    \section{Lessons Learned}

    The lesson learned: to solve a problem, test your target population.

    As inspectors collect data, Bluetana can learn new features and attempt more ways of finding skimmers.

    As criminals adapt, WM staff will still be the ones going to stations. This would actually make the deployment of a persistent solution not too hard.

    Looking for documents that have a new formal structure: information in the document class, rather than input.
    - Look for word overlap in the document pages, classify by levenstien distance

    \section{The Design of Bluetana}

    Working from the data covered in this section, one can begin to develop ideas for potential solutions to the skimming problem.  The next chapter will discuss the design of an application, Bluetana, which serves to passively and actively detect skimmers, allowing inspectors to more easily check the pumps and avoid errors.  These reports also indicate other avenues for solving the skimmer problem, such as persistent devices or training for gas station employees on signs of tampering. 

    \section{Related and Future Work}

    In this chapter, both keyword and phrase-based analysis were inaccurate in semantic classification. Random sampling was closer in determining the success rate of skimmer investigations. These same techniques were used to understand skimmer construction and investigator behavior. Since the documents are rich text by investigators, manual analysis was still needed to answer questions such as "Do inspectors check pumps with security seals?". A system for answering these queries would reduce the need for manual analysis. Similar tasks are already performed by the content-based filtering of recommendation systems. The classic content-based recommender system uses word frequency and a user profile (e.g. demographics) \cite{pazzani1999framework}. A query could take the place of a user profile. However, this approach requires a semantic understanding of the document and the query.  A 2011 survey by Lops notes several approaches for representing this semantic information. An example would be weighting documents by the frequency of rare terms \cite{lops2011content}. However, at the time of writing, a system for performing the analyses presented by Lops in a free, quick, and automated manner does not seem to exist. In our case, Mechanical Turk or a trained ANN may have been enough to answer most questions. However, answering each question would have required a separate round of testing or training.

\section{Summary}
\section{Acknowledgements}

