\chapter{Understanding Field Agent Behavior}\label{chap:2}
\begin{quote}
  ``It is a capital mistake to theorize before one has data.'' \\
  --- Sir Arthur Conan Doyle, \emph{Sherlock Holmes}
\end{quote}

This chapter surveys gas pump inspection reports from the Arizona Department of Weights and Measures (AZDWM).
It begins by attempting to attain descriptive statistics related to skimming from these documents.
Challenges in attaining these statistics lead into discussion of data acquisition methodologies.
This chapter then highlights discoveries about inspections and skimmers contained within the documents.
It concludes with a summary of the motivation for Bluetana's development provided by the documents and future work.

Analysis of the data provided by AZDWM proved to be difficult, but had two primary benefits.
The first was a categorical understanding of current investigative techniques: notes provided by investigators offer insight into how they perform inspections.
The second was an understanding of the potential avenues of skimmer detection.
Photos and forms included in the reports reveal details of skimmer construction.
These details suggest Bluetooth modules are commonly used and that Bluetooth is a potentially effective route for detection.

Finally, This chapter functions as a \emph{case study} of exploratory data analysis.
It does not provide universal techniques; instead, it compares multiple approaches to the analysis of gas station inspection documents.
This structure allows the chapter to demonstrate some ways \emph{not} to do data analysis on this type of data set.
It does so by comparing tempting, flawed data analysis techniques to ground-truth data.

\section{Survey Background}

Inspection report PDFs from the AZDWM are accessible through a queriable web interface (\url{https://ctutools.azda.gov/PdfOriginals/}).
The data set of reports was retrieved via an html parser and batched \texttt{wget} requests.
The PDFs downloaded from this source include documents unrelated to inspections.
PDFs relating to inspection reports follow a naming scheme of \texttt{\{BMF \#\}-\{Inspection \#\}.(pdf|PDF)}.
A BMF, or Business Master File, number is a unique identifier given to each business by the AZDWM \cite{azdwmLicensing}.
It is not clear from the filenames which reports pertain to skimming.
Thus, classifying and analyzing these reports requires parsing the PDFs themselves.
Luckily, reports contain a header that indicates the origin of the inspection.

There are~\totalAZDWMpdfs~inspection report PDFs available on the AZDWM website.
The oldest report available is from July 2010.
This survey will focus on reports filed from the beginning of 2016 to the end of 2018.
This amounts to a total of~\upperAZDWMpdfs~reports.
By restricting analysis to the past three years of data, we preserve the relevance of the study to the present day.
Table~\ref{tab:overview-azdwm-stats} provides overview statistics on the documents.

\begin{table}
  \centering
  \noindent
  \begin{tabular}{l|c}
    \toprule
    Total Number of PDFs                                         & \upperAZDWMpdfs  \\
    \midrule
    Number of PDFs with Parsable Origin                          & \numParsableAZDWMpdfs   \\
    \midrule
    Number of PDFs Originating from a Skimmer Inspection         & \numSKIOrig  \\
    \midrule
    Number of PDFs with the word ``skimm''                       & \numSkimWord  \\
    \midrule
    Success Rate Reported by the AZDWM (Unhinted)                     & 1.5\%  \\
    \bottomrule
  \end{tabular}
  \caption{
    Overview statistics on the documents from AZDWM gas station inspection reports.
    Only a portion of the documents are parsable.
    Some non-skimmer inspections include checks for skimmers.
  }
  \label{tab:overview-azdwm-stats}
\end{table}

A primary goal of this survey is to understand skimmer inspections.
For instance, how rigorously inspectors investigate pumps and the time it takes to do so
(Section~\ref{sec:inspector-behavior}).
Another goal was to quantify the hit rate of skimmer inspections
(Section~\ref{sec:document-data-extraction});
this provides a measure of how common skimming is.
Answers to these questions can drive improvements in detection methods 
(Section~\ref{sec:bluetana-motivation}).

\section{Understanding the Documents}\label{sec:understanding-the-documents}

Upon examining the PDFs, we find the information contained within is highly unstructured.
For example, the documents have an inconsistent use of the 198 failure code.
This code indicates a skimmer was found.
Figure~\ref{fig:198-usages} depicts two different uses of this code.
There also exist successful skimmer inspections with no 198 code in the document at all 
\cite{13529-268466}.
Unfortunately, this indicates a single regular expression search for successful investigations is nontrivial.
Additionally, there are latent ambiguities in the data collected.
Many documents do not state whether a found skimmer was internal or external.
They also do not state whether the AZDWM was responsible for the skimmer's detection.
For instance, a station owner or service tech can discover a skimmer and ``call it in''.
Hereafter, reports triggered by individuals outside the AZDWM  are referred to as ``hinted''.

\begin{figure}
  \centering
  \includegraphics[width=4.25in]{pics/198-usages.png}
  \caption{
    Inconsistent use of the 198 error code.
    In the top report, the code is included in the inspection notes.
    In the bottom image, a separate field used for fail codes contains the 198.
  }
  \label{fig:198-usages}
\end{figure}

The exact skimmer inspection methodology is not noted in any of the reports.
There are, however, hints within the inspection notes and the document structure.
For instance, vapor recovery
\footnote{Checking the pumps to make sure they do not leak gasoline vapors into the atmosphere.}
reports contain a pre-inspection checklist.
This checklist contains a check for skimmers
(Figure~\ref{fig:check-for-skimmers}).
The reports do not contain information on the whether skimmer investigations occur alongside other inspections.
However, the AZDWM site notes skimmer inspections are always performed during pump inspections
\cite{azdwmSkimmers}.
Thus, any report that includes a pump inspection includes a skimmer check.

\begin{figure}
  \centering
  \includegraphics[width=4.25in]{pics/inspection-checklist.png}
  \caption{
    Section of the inspection reports which demonstrates information on the pre-inspection checklist.
    In this case, no skimmer was found.
  }
  \label{fig:check-for-skimmers}
\end{figure}

The inspection reports also contain information on skimmer construction.
Some report forms have a checkbox for tagging whether a skimmer is SMS or Bluetooth enabled
(Figure~\ref{fig:bluetooth-or-gsm}).
However, inspectors may not have a perfect sense of this.
AZDWM has informed us investigators do not to remove any tape used to encase or hide the skimmer in the pump.
This is done to preserve fingerprints 
\cite{20340-269297}.
Some documents do attempt to correlate Bluetooth features to discovered skimmers. 
For example, MAC addresses and skimmer names
(Figure~\ref{fig:mac-address-report}).
During the Bluetana study, these hints were found to be inaccurate.
However, they do illustrate some investigator awareness of skimmers' Bluetooth capabilities.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{pics/bluetooth-or-gsm.png}
  \caption{
    Some inspection forms include a checkbox for the exfiltration mechanism of the skimmer.
    While the selection of SMS may not be accurate, it does indicate not all skimmers use Bluetooth.
  }
  \label{fig:bluetooth-or-gsm}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{pics/mac-address-report.png}
  \caption{
    Section of the inspection reports noting a potential MAC address for a skimmer.
    Follow up investigation found this MAC address to be uncorrelated with skimmer discovery.
  }
  \label{fig:mac-address-report}
\end{figure}

\subsection{Understanding Document Origins}\label{sec:understanding-origins}

Inspection reports have~\numorigins~different origin headers.
Table \ref{tab:explanations-of-origins}
contains statistics and descriptions of the different report types.
Regular, scheduled inspections are the most common, followed by skimmer inspections. 
Complaint-triggered inspections are also common. 
Unfortunately, determining whether a complaint was about a skimmer installation is difficult.
Complaints unrelated to skimmers can include skimmer checks and the word 
\texttt{skimm} \cite{7690-290206}.
Additionally, note that the total number of documents is greater than number of parsable PDFs.
This is because some documents contained multiple inspection reports concatinated.

\begin{table}
  \centering
  \begin{tabular}{@{}lcr@{}}
    \toprule
    Origin Header & Meaning                        & Number of Documents \\ \midrule
    SCH           & Regular Scheduled Inspection   & \numSCHOrig \\
    SKI           & Skimmer Inspection Report      & \numSKIOrig \\
    COM           & Complaint Triggered Inspection & \numCOMOrig \\
    REI           & Price Posting Inspection       & \numREIOrig \\ 
    VDA           & Meter Licensing Inspection     & \numVDAOrig \\
    VAN           & Vapor Recovery Inspection      & \numVANOrig \\
    COL           & Licensing Fee Collection       & \numCOLOrig \\
    SPC           & Fuel Quality Inspection        & \numSPCOrig \\ \bottomrule
  \end{tabular}
  \caption{
    Summary of skimmer inspection form data origins and their occurrence rate.
    Reports are submitted most often for scheduled and skimmer-specific inspections.
  }
  \label{tab:explanations-of-origins}
\end{table}


\begin{figure}
  \lstset{language=bash}
  \begin{lstlisting}
    grep -li "skimm" $(grep -li "origin[ :]*\s*com" *.txt)
  \end{lstlisting}
  \caption{
    Example regular expression used to match document types.
    In this case, the script finds complaint triggered reports that mention skimmers.
  }
  \label{fig:grep-code}
\end{figure}

A regular expression was built to extract the origin header the documents
(Figure~\ref{fig:grep-code}).
This excluded~\numNonParsableAZDWMpdfs~from Table
\ref{tab:explanations-of-origins}. 
Most of these documents have missing or incorrect ToUnicode CMaps.
Documents with embedded fonts include this mapping for the extraction of Unicode content
\cite{toUnicode-mapping-tutorial}.
High-quality optical character recognition (OCR) has potential to correct these documents. 
This analysis was attempted and is detailed in Section~\ref{sec:complications-of-ocr}.
\numPressureDecayTest~of the documents did not contain the first, primary report page.
These correspond to Pressure Decay Test forms, used when testing the pumps for leaks.

\subsection{Preforming OCR on~\numNonParsableAZDWMpdfs~PDFS}\label{sec:complications-of-ocr}

The OCR to correct the missing ToUnicode CMaps was somewhat effective.
After performing this analysis, the number of unrecognized origin headers dropped to
\amountofparsableoriginsafterocr.
The OCR was performed using \texttt{ocrmypdf} which operatings using the Tesseract library
\cite{smith2007overview}.
The \texttt{-clean} and \texttt{--rotate-pages} flags were used for document cleaning and orientation detection.
The final results table is included in Figure~\ref{tab:final-orig-results}.
Additionally,~\finalnumSkimWord~ reports contained the word ``skimm''.

\begin{table}
  \centering
  \begin{tabular}{@{}lr@{}}
    \toprule
    Origin Header & Number of Documents \\ \midrule
    SCH           & \finalnumSCHOrig \\
    SKI           & \finalnumSKIOrig \\
    COM           & \finalnumCOMOrig \\
    REI           & \finalnumREIOrig \\ 
    VDA           & \finalnumVDAOrig \\
    VAN           & \finalnumVANOrig \\
    COL           & \finalnumCOLOrig \\
    SPC           & \finalnumSPCOrig \\ \bottomrule
  \end{tabular}
  \caption{
    OCR corrected inspection form origins.
    The ratios of each report type are approximately the same as before OCR.
    However, vapor recovery and complaint based inspections jumped in number.
  }
  \label{tab:final-orig-results}
\end{table}

\emph{All} the~\upperAZDWMpdfs~PDFs underwent OCR.
The analysis could have isolated the~\numNonParsableAZDWMpdfs~ unparsable PDFs only.
However, it was unclear whether the entire set of PDFs were non-corrupted. 
Additionally, OCR allowed for parsing the cleanly handwritten reports.
With EC2, this analysis took~\ectwohoursspent~hours on a 72 core machine. 
The cost was~\ectwodollarsspent.

A downside of OCR is that it has trouble inferring the layout of text on the page.
Figure~\ref{fig:misplaced-pdftotext} compares the layout of the original report to it's OCRed duplicate.
In this case, the OCR version does not maintain the document's original layout.
However, it does contain the investigator's name, which was originally unparsable.
Incorrect layout inference made the generation of regular expressions for page content nontrivial.
To solve this problem, I developed a more sophisticated tool for text extraction.
This tool, data-extract-PDF~\cite{dataExtractPdf}, allows the automated extraction of PDF sections.
Unfortunately, this tool was not used for the final analysis in this project.
However, another project with a large number of PDFs uses a variant of data-extract-PDF for content extraction.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{pics/misplaced-pdftotext.png}
  \caption{
    Example of a report \texttt{pdftotext} with layout after OCR.
    On the left hand side is the OCRed version with flawed layout recognition.
    In the middle is the original document.
    On the right is the output of \texttt{pdftotext} befor OCR.
  }
  \label{fig:misplaced-pdftotext}
\end{figure}

\subsubsection{Open Problems in Optical Character Recognition}

Additional work is needed on document content extraction. 
It may be possible to build an inference system which can correct the CMap issues seen in this group of PDFs.
This would a benefit to search engine document indexing and empirical research.
Better document layout recognition would also benefit this research.
Scene text recognition has been a longstanding open problem. 
The first public data set, the ICDAR Robust Reading challenge, was created in 2003 
\cite{lucas2003icdar}. 
However, these data sets focus on images and not on documents.
Recent advances in Visual Question Answering (VQA) could be used for this purpose.
Last year, Anderson presented Bottom-Up and Top-Down attention models.
\cite{anderson2018bottom}.
These models operate at the level of objects and image regions, rather than uniform grids.
This technology may be adaptable to document region detection.

\section{Document Data Extraction}\label{sec:document-data-extraction}

Despite parsing difficulties, the documents contain useful information about skimmer investigations.
Of particular interest is the number of skimmer inspections which discover skimmers.
A manual analysis of all the documents would be required to answer this question with perfect precision.
Thus, several alternative approximations were attempted.
Each alternative method and the resulting approximation are detailed in Table
\ref{tab:success-rates}.
Details about these methods are included in the next three subsections.
The AZDWM was also contacted directly for the ground truth data. 
Their reported ``hit'' rate for unhinted inspections was 
\percentSkimmersToStations.

\begin{table}
  \centering
  \begin{tabular}{lcr}
    \hline
    Method                & Inspections Considered & Unsuccessful Inspections \\ \hline
    Keyword Analysis      & \finalnumSkimWord      & \finalnumNoSkimWord      \\
    Phrase-based Analysis & \finalnumSkimWord      & \finalnumPhraseFilter    \\
    Random Sampling       & \numDocumentsSampled   & \finalnumSampled         \\ \hline
  \end{tabular}
  \caption{
    The skimmer detection success rates as reported by different methods for document analysis.
    Both phrase based and keyword based analysis are inaccurate.
    However, random sampling is accurate to $\pm 2.6\%$ with 99\% confidence.
  }
  \label{tab:success-rates}
\end{table}

\subsection{Keyword-based Analysis}

The first attempt at skimmer detection rate estimation was keyword based.
The intuition was to subtract the reports with the words ``no skimm'' from the reports with the word ``skimm''. 
This number deviates from the ground truth for trivial reasons. 
For one, the pre-inspection checklist includes the term ``skimm''. 
The reported skimmer detection success rate based upon this metric was \skimmerwordbasedsuccessrate.
The actual detection rate for unhinted inspections is much lower. 
Using a keyword search misses semantic details of the content. 
For instance, the skimmer may have been discovered before AZDWM was called.

\subsection{Phrase-based Analysis}

A phrase-based approach was also evaluated.
This looked for phrases to classify the document rather than keywords.
Documents with these phrases were subtracted from those with the word ``skimm''.
\numPhrasesUsed~phrases were used in total.
These more complex signifiers allow for the preservation of more semantic content.
The corpus of phrases is included in Table~\ref{tab:phrase-corpus}.
To build this table, the documents were randomly sampled and manually analyzed.
Negative phrasing was used rather than positive phrasing.
This is because positive phrases are often subsets of negative phrases, e.g. ``[no] skimmer found''
In this case, the percentage discovery rate reported by this technique was~\phrasebasedsuccessrate. 
This is closer to the the ground truth reported by the AZDWM. However, it still suffers many of the same drawbacks as the keyword based approach.

\begin{table}
  \centering
  \begin{tabular}{@{}l@{}}
    \toprule
    \texttt{pumpsinspectedforskimmers,externalandinternal;nonefound} \\
    \texttt{skimmerswithnegativeresults} \\
    \texttt{noskimmerfund} \\
    \texttt{checkedthesiteforskimmersanddidnotlocateany} \\
    \texttt{skimmers;nonefound} \\
    \texttt{skimmersbutnonewerefound} \\
    \texttt{checkforskimmers0found} \\
    \texttt{checkforaskimmingdevicewithnegativeresults} \\
    \texttt{noskimmerinspectionperformed} \\
    \texttt{noinspectionforinteriorskimmer} \\
    \texttt{skimmernonewalkedalone} \\ 
    ... \\ \bottomrule
  \end{tabular}
  \caption{
    Subset of the corpus of phrases used to determine whether a skimmer was found.
    The phrases are in lowercase and without spaces to simplify parsing.
    Misspellings are accurate to the original text produced by OCR.
  }
  \label{tab:phrase-corpus}
\end{table}

This method was effective because a small number of investigators generated the reports.
The phrases captured the individual idiosyncrasies of investigators. 
Each inspector will, for a time, have \emph{their way} of signifying whether they found a skimmer or not.
However, phrase based analysis remains inaccurate. 
The are many subtle indicator phrases that an inspection was not random. 
Some of these, such as ``owner found skimmer,'' can be captured.
Others are report-specific and cannot be included without manual analysis of every document.
This makes it difficult to determine whether the phrase corpus is unbiased.

\subsection{Random Sampling}

The next method attempted was random sampling of documents containing the word ``skimm''.
This approximated a skimmer detection success rate of \randomsamplesuccessrate.
($\pm 2.6\%$ with 99\% confidence).
Manual analysis of the sampled documents allowed the removal of hinted reports.
Police, gas station owners, and credit companies hinted five of the seven reports.
This approach also won out in the time taken to perform the analysis. 
Classifying this small number of reports, however, took only two hours.
Finding a ``reasonable'' phrase corpus took more time.
These approaches show different prediction convergence behavior as time progresses.
Random sampling zeroes in on a mean estimate, while phrase-based analysis moves step-wise. 
The latter of the two is only rigorous under restricted circumstances.
Figures \ref{fig:phrase-based-accuracy-num-terms} and \ref{fig:random-sampling-accuracy-num-reviewed} provide this comparison. 

\begin{figure}
  \centering
  \includegraphics[width=4.25in]{plots/phrase-based-accuracy-num-terms.pdf}
  \caption{
    Probability of skimmer detection approximated by the phrase-based model per phrase added.
    The approximation has a large spike upon addition of the phrase ``no skimmer''.
    Otherwise, phrases added have little impact on the reported success rate.
  }
  \label{fig:phrase-based-accuracy-num-terms}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{plots/random-sampling-accuracy-num-reviewed}
  \caption{
    The convergence of the estimated skimmer detection probability from random sampling.
    The filled portion of the plot depicts a 95\% confidence interval. 
  }
  \label{fig:random-sampling-accuracy-num-reviewed}
\end{figure}

The findings show naive automated analysis is inadequate in some empirical measurement domains.
Automated approaches can be tempting in their formality.
However, they can also result in severe statistical bias.
Manual inspection \emph{can} contain bias as well.
For some studies, such as this one, the accuracy of random sampling suggests bias is not an issue.

\section{Describing Inspections and Skimmers}\label{sec:describing-inspections-skimmers}

By looking at the sample of documents, we get a broader understanding of skimming.
First, complaints and hints from customers are somewhat helpful when detecting skimmers.
Additionally, internal, Bluetooth enabled skimmers are common.
Finally, manual skimmer inspections are slow: often taking 30 minutes or more.

\subsection{Inspection Report Generation Bias}\label{sec:inspector-behavior}

Random sampling was also able to determine the effectiveness of hints.
I considered a hint to be anything that suggests to the inspector that there is a skimmer.
This includes owners calling in AZDWM to report a found skimmer.
It also includes complaints filed about skimming which trigger an inspection.
Finally, AZDWM also recieve hints from credit companies and local PD.
\randsamplehinted~of the inspections in the \numDocumentsSampled sampled documents were hinted.
Five of these hints were correct, making the efficacy of hints 29.4\% for this sample.

Additionally, some documents show inspectors are not following best practices.
This includes checking the pumps even if there are security seals in place
(Figure~\ref{fig:no-check-security-seals}).
Criminals can buy pump security seals online \cite{gas_pump_seals}.
Therefore inspectors should check pumps even if seals are in place.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{pics/no-check-security-seals}
  \caption{
    Instance of an inspector not checking for skimmers because of security seals.
    In other cases, inspectors did not check locked or alarmed pumps.
  }
  \label{fig:no-check-security-seals}
\end{figure}

\subsection{Inspection Time}

Finally, skimmer inspections take a long time.
I sampled \numSkiRandomSampled SKI-origin reports and recorded the time taken in the inspection. 
Figure~\ref{fig:insp-time-cdf} presents a CDF of the inspection times.
The average inspection time was \avgInspectionTimeSample ($\sigma = $\stddevInspectionTime.
If there were a way to speed up inspection times, it could improve skimmer detection.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{plots/insp-time-cdf}
  \caption{
    Inspection times for \numInspectionTimesConfidence randomly sampled inspections. TODO details
  }
  \label{fig:insp-time-cdf}
\end{figure}

\subsection{Skimmer Construction}\label{sec:skimmer-construction}

Inspection documents can also provide hints on skimmer construction.
As was seen in Section~\ref{sec:understanding-the-documents}, some documents included potential MAC addresses and names. 
Additionally, \numSkimmerInspBluetooth of \numSuccessfulSkimmerInsp skimmers found above were Bluetooth capable.
From this, we can isolate Bluetooth as a potential route of detection. 
Additionally, all the skimmers discovered within the sampled reports were internal.
Thus, a robust method of internal skimmer detection may have high impact.

\section{The Design of Bluetana}\label{sec:bluetana-motivation}

This chapter's research motivates development of a Bluetooth application for skimmer detection.
In the next chapter, I will detail the design of such an application, named Bluetana.
We know from the reports internal, Bluetooth-enabled skimmers are common.
Because of this, Bluetooth scanning has the potential to discover these skimmers.
Additionally, we know that inspections currently take a significant amount of time.
Not only do inspections take time, they may not be comprehensive.
Thus, a faster method of detection which is more comprehensive would be useful.
Bluetana accomplishes both of these tasks.
Finally, inspectors drive by and visit a large number of stations.
Not every inspection is a pump inspection, as well
(Section~\ref{sec:understanding-origins}).
A passive Bluetooth scanning application would allow for passive skimmer checking.

\section{Related and Future Work}\label{sec:chap2-related}

In this chapter, both keyword and phrase-based analysis were inaccurate in semantic classification.
Random sampling was closer in determining the success rate of skimmer investigations.
These same techniques were used to understand skimmer construction and investigator behavior.
Since the documents are rich text by investigators, manual analysis was still needed to answer questions such as ``Do inspectors check pumps with security seals?''.
A system for answering these queries would reduce the need for manual analysis.
Similar tasks are already performed by the content-based filtering of recommendation systems.
The classic content-based recommender system uses word frequency and a user profile (e.g. demographics) \cite{pazzani1999framework}.
A query could take the place of a user profile.
However, this approach requires a semantic understanding of the document and the query.
A 2011 survey by Lops notes several approaches for representing this semantic information.
An example would be weighting documents by the frequency of rare terms \cite{lops2011content}.
However, at the time of writing, a system for performing the analyses presented by Lops in a free, quick, and automated manner does not seem to exist.
In our case, Mechanical Turk or a trained ANN may have been enough to answer most questions.
However, answering each question would have required a separate round of testing or training.

Despite current efforts and the design of Bluetana, skimming will remain a problem.
The GasBuddy database reports that there are \numGasBuddyStation in the United States. 
It would be difficult for investigators to cover all stations at all times.
However, preventative mechanisms are being developed and implemented.
Newer Veriphone pumps operate using a chip-only reader.
Authorities in other countries have recovered skimmers which operate on chip-based POS
systems \cite{atm_shimmers}.
These devices, called shimmers, may allow criminals to continue skimming.
Pump alarms and advanced locks can also prevent skimming.
However, time will be needed to upgrade all the pumps in the United States.

\section{Summary}
\section{Acknowledgements}

